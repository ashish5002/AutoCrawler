# **GeminiScraper ğŸ•·ï¸**  
**AI-Powered Multilingual Web Scraper using Selenium & Google Gemini AI**  

ğŸš€ **GeminiScraper** is an advanced web scraping tool that combines **Selenium** with **Google Gemini AI** to extract structured multilingual content from dynamic websites. It ensures **clean, meaningful, and structured data processing**, making it ideal for research, automation, and data analysis.

---

## **âœ¨ Features:**  
âœ… **Multilingual Content Extraction** â€“ Supports **English, Odia**, and other available languages.  
âœ… **Selenium-Based Scraping** â€“ Handles **dynamic, JavaScript-heavy websites** efficiently.  
âœ… **AI-Powered Content Structuring** â€“ Uses **Google Gemini AI** to process raw HTML into structured **JSON**.  
âœ… **Smart Anti-Bot Evasion** â€“ Implements **random delays, user-agent rotation, and human-like browsing** to avoid detection.  
âœ… **Headless Mode Support** â€“ Runs in the background for **efficient and seamless scraping**.  
âœ… **Recursive Link Crawling** â€“ Extracts and follows **internal links** for deep scraping.  
âœ… **Clean JSON Output** â€“ Structured data including **titles, main content, links, and contact information**.  

---

## **ğŸ“ Installation**  
Clone the repository and install dependencies:  

```bash
# Clone the repository
git clone https://github.com/yourusername/GeminiScraper.git  
cd GeminiScraper  

# Create a virtual environment (recommended)
python -m venv venv  

# Activate the virtual environment:
# On Windows:
venv\Scripts\activate  
# On macOS/Linux:
source venv/bin/activate  

# Install required dependencies
pip install -r requirements.txt  
```

---

## **âš¡ Usage**  
### **1ï¸âƒ£ Configure Base URL**  
Edit `scraper.py` to define your target website:

```python
base_url = "https://your-target-website.com"
```

### **2ï¸âƒ£ Run the Scraper**  
Execute the following command to start scraping:

```bash
python scraper.py  
```

### **3ï¸âƒ£ View Extracted Data**  
Scraped content is saved in `crawl_results.json` in a structured format:

```json
{
  "https://example.com/page1": {
    "url": "https://example.com/page1",
    "english": {
      "title": "Example Page",
      "content": "This is an example extracted text.",
      "links": ["https://example.com/about"],
      "contact": "info@example.com"
    },
    "odia": {
      "title": "à¬‰à¬¦à¬¾à¬¹à¬°à¬£ à¬ªà­ƒà¬·à­à¬ à¬¾",
      "content": "à¬à¬¹à¬¿à¬Ÿà¬¿ à¬à¬• à¬‰à¬¦à¬¾à¬¹à¬°à¬£ à¬Ÿà­‡à¬•à­à¬¸à¬Ÿà­ã€‚"
    }
  }
}
```

---

## **ğŸ›  Configuration**  
### **Environment Variables**  
Create a `.env` file to store your **Google Gemini API Key**:

```env
GOOGLE_API_KEY=your_api_key_here
```

### **Logging & Debugging**  
All activity is logged in `crawler.log` for debugging purposes.

---

## **ğŸ“š File Structure**  
```
GeminiScraper/
â”‚â”€â”€ venv/                   # Virtual environment (excluded from Git)
â”‚â”€â”€ crawler.log             # Log file for debugging
â”‚â”€â”€ requirements.txt        # Dependencies
â”‚â”€â”€ scraper.py              # Main web scraper script
â”‚â”€â”€ .gitignore              # Ignores unnecessary files
â”‚â”€â”€ .env                    # API keys (excluded from Git)
â”‚â”€â”€ README.md               # Project documentation
```

---

## **ğŸŒ Use Cases**  
- **News Aggregation** â€“ Extract headlines and articles from multiple sources.
- **Academic Research** â€“ Collect multilingual data for NLP and AI projects.

---

## **ğŸ‰ Contributing**  
Pull requests are welcome! If youâ€™d like to improve this project, please open an issue first to discuss proposed changes.

---



ğŸ‰ **Happy Scraping!** ğŸš€

